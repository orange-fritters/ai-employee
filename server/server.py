import json
import os
from typing import List

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, RedirectResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles

from model.io_model import IOModel
from model.bm25.ensemble import Ensemble
from model.embed.multiturn_model import MultiTurn

from model.embed.embed_prompt import get_answer_from_question
import model.utils.convert_prompt as get_prompt
from model.utils.schemas import Query, Search, SingleString, History, RankTitle
from model.utils.get_response_openai import get_response_openai, get_response_prompted

# App Setting Section

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

io_model = IOModel('model/files/info_sheet.csv')
multiturn_model = MultiTurn()
ensemble = Ensemble()


# Single-turn Section

@app.post("/api/summary")
async def get_summary(query: SingleString):
    """From a title, return a pre-generated summary of the article. """
    return io_model.get_summary(query.query)


@app.post("/api/gpt-summary")
async def get_chat(title: SingleString):
    """From a title, return a summary of the article generated by llm."""
    content, target = io_model.get_content_target(title.title)

    prompt = get_prompt.get_summary(target, content, title.title)
    return StreamingResponse(get_response_openai(prompt), media_type="text/event-stream")


@app.post("/api/query")
async def get_chat_response(query: Query):
    """ Endpoint for retrieve a documentand answer a query."""
    filename = io_model.get_filename(query.title)
    filedir = os.path.join('articles', filename)
    with open(filedir, 'r', encoding='utf-8') as f:
        document = f.read()

    prompt = get_prompt.get_answer_from_document(document, query.query)
    return StreamingResponse(get_response_openai(prompt), media_type="text/event-stream")


@app.post("/api/recommendation")
async def get_recommendation(query: SingleString):
    """ from query, return a list of titles of recommended service. """
    recommendations = ensemble.get_topN_title(query.query)
    return json.dumps(recommendations)


@app.post("/api/search")
async def get_search(search: Search):
    """
    Endpoint for retrieve and answer a search query.

    Args:
        search (Search): A Pydantic model representing the search query.
    Returns:
        StreamingResponse: A streaming response containing the search results.
    """
    # Function code here
    titles = ensemble.get_topN_title(search.query)
    titles = [RankTitle(**title) for title in titles]
    options = multiturn_model.get_contents_from_title(titles)
    prompt = get_answer_from_question(search.query, options)
    return StreamingResponse(get_response_prompted(prompt), media_type="text/event-stream")


# Multi-turn Section

@app.post("/api/multi-turn/decide-sufficiency")
async def decide_sufficiency(titles: List[RankTitle],
                             history: List[History]):
    """
    Endpoint for decide whether the information is sufficient.
    multiturn model asks llm for the sufficiency of information.
    Args:
        titles (List[RankTitle]): A list of RankTitle.
        history (List[History]): A list of History.
    Returns:
        json: A json object containing the decision result.
    """
    # titles : [RankTitle(title='title_of_service', rank=0), RankTitle...]
    # history : [History(role='uesr', content='query_from_user'), History...]
    result = multiturn_model.decide_information_sufficiency(titles, history)
    return json.dumps(result)


@app.post("/api/multi-turn/question")
async def get_new_question(titles: List[RankTitle],
                           history: List[History]):
    """ Endpoint for generating a new question to ask user. """
    result = multiturn_model.get_question_from_history(titles, history)
    return json.dumps(result)


@app.post("/api/multi-turn/recommendation")
async def get_new_recommendation(titles: List[RankTitle],
                                 history: List[History]):
    """ Endpoint for generating a new recommendation given a conversation history. """
    result = multiturn_model.get_recommendation_new_history(history)
    print(result)
    return json.dumps(result)


@app.post("/api/multi-turn/answer")
async def get_answer(titles: List[RankTitle],
                     history: List[History]):
    """ Endpoint for generating an answer given a conversation history."""
    result = multiturn_model.get_answer_from_history(titles, history)
    return json.dumps(result)


# View document Section

@app.get("/api/articles/view/{id}")
async def view_article(id: str):
    """ Redirection for viewing a document. """
    return RedirectResponse(url=f'/articles/{id}')


@app.get("/articles/{id}")
async def get_article(id: str):
    """ Endpoint for viewing a document. """
    filename = io_model.data.iloc[int(id)]['filename']
    filepath = os.path.join('articles', filename)
    return FileResponse(filepath, media_type='text/html')


# Static Section

app.mount("/", StaticFiles(directory="build", html=True), name="build")
